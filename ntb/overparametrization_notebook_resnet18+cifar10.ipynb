{"cells":[{"cell_type":"markdown","metadata":{"id":"7u-HxbbycxkD"},"source":["# OVERPARAMETRIZATION THESIS\n","\n","Deep Double Descent was proven to be related to noise (or actually to model misconfiguration) here:<br>\n","https://openai.com/research/deep-double-descent\n","\n","**The goal is to reproduce this behaviour shown in the paper and to check if using noise-robust losses it is actually reduced.**\n","\n","\n","*Thesis student*: Carmignani Federico (1845479)\n","\n","*Tutors*: Siciliano Federico and Bucarelli Maria Sofia\n","\n","*Professor:* Silvestri Fabrizio"]},{"cell_type":"markdown","metadata":{"id":"2nRCG0Q8347G"},"source":["## Preparation phase\n","\n","\n","1.   Installation from GitHub\n","2.   Connection to Google Drive\n","3.   Paths definition and imports\n","\n","There are 2 possibilities for using this notebook:\n","\n","*   Run locally\n","\n","In this case we have 2 chances:\n","\n","1.   Download through pip install from GitHub, then import it using import keyword and use it.\n","2.   Download the code locally from GitHub and from the notebook define the paths to these sources (code to be adjusted).\n","\n","*   Run in Colab\n","\n","1.   Download through pip install from GitHub, then import it using import keyword and use it (HERE).\n","2.    Download the code locally from GitHub into the src folder in Google Drive and from the notebook define the paths to these sources (code to be adjusted).\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"c81IM9YmWpCp"},"source":["### Connection to Google Drive\n","The code is a Python snippet designed to connect Google Drive to a Google Colab notebook. It checks if connect_to_drive is set to True, and if so, it imports the necessary library and mounts Google Drive to the /content/gdrive directory using Google Colab's drive.mount() function. The user will be prompted to authorize the connection through a popup window."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31291,"status":"ok","timestamp":1700052969157,"user":{"displayName":"federico carmignani","userId":"12157280803704243344"},"user_tz":-60},"id":"QgLWUVMAWpCq","outputId":"354cc33f-1a37-4708-dbdb-7fecb1550b22"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["# Set connect_to_drive to True if you want to connect to Google Drive.\n","connect_to_drive = True\n","\n","# If connect_to_drive is True, connect to Google Drive using the google.colab library.\n","# This will prompt a popup window where you'll need to authorize access to your Google Drive.\n","if connect_to_drive:\n","    from google.colab import drive\n","\n","    # Mount the Google Drive to the '/content/gdrive' directory in the Colab environment.\n","    # The 'force_remount=True' parameter ensures that if the Drive is already mounted,\n","    # it will be remounted to refresh the connection.\n","    drive.mount('/content/gdrive', force_remount=True)"]},{"cell_type":"markdown","metadata":{"id":"naL0RCcnt2qq"},"source":["### Installation of packages\n","This code block installs Python packages and libraries using the pip package manager. It checks the value of the connect_to_drive variable, and if it is True, the code assumes that the user wants to install the specified packages (otherwise commands assumed done via console manually). Here's a breakdown of the installation process:\n","\n","1.   git+https://github.com/fed21/easy_lightning.git: This command installs Python packages called data_utils, exp_utils and torch_utils.\n","2.   pip install pytorch_lightning: Finally, this command installs the pytorch_lightning library, which is a popular and easy-to-use PyTorch wrapper that simplifies the process of training deep learning models.\n","\n","Overall, this code is meant to set up the required dependencies for a specific project, and by setting connect_to_drive to True, the user can conveniently install these packages in their environment. Note that the installation process might take a few moments to complete depending on the network speed and the size of the packages."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"GEk1dTczt2qq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700052996526,"user_tz":-60,"elapsed":27376,"user":{"displayName":"federico carmignani","userId":"12157280803704243344"}},"outputId":"dad8337e-25bd-4eb3-f7a6-270ebe0f220c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/fed21/easy_lightning.git\n","  Cloning https://github.com/fed21/easy_lightning.git to /tmp/pip-req-build-d3jcmwxp\n","  Running command git clone --filter=blob:none --quiet https://github.com/fed21/easy_lightning.git /tmp/pip-req-build-d3jcmwxp\n","  Resolved https://github.com/fed21/easy_lightning.git to commit 26dd88f8a16a9e078bdb15bd07060beb7103618a\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from Easy-Lightning==0.0.1) (2.1.0+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from Easy-Lightning==0.0.1) (0.16.0+cu118)\n","Collecting torchmetrics (from Easy-Lightning==0.0.1)\n","  Downloading torchmetrics-1.2.0-py3-none-any.whl (805 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.2/805.2 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pytorch_lightning (from Easy-Lightning==0.0.1)\n","  Downloading pytorch_lightning-2.1.1-py3-none-any.whl (776 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 kB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from Easy-Lightning==0.0.1) (1.5.3)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->Easy-Lightning==0.0.1) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->Easy-Lightning==0.0.1) (2023.3.post1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas->Easy-Lightning==0.0.1) (1.23.5)\n","Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning->Easy-Lightning==0.0.1) (4.66.1)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning->Easy-Lightning==0.0.1) (6.0.1)\n","Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning->Easy-Lightning==0.0.1) (2023.6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning->Easy-Lightning==0.0.1) (23.2)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning->Easy-Lightning==0.0.1) (4.5.0)\n","Collecting lightning-utilities>=0.8.0 (from pytorch_lightning->Easy-Lightning==0.0.1)\n","  Downloading lightning_utilities-0.9.0-py3-none-any.whl (23 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->Easy-Lightning==0.0.1) (3.13.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->Easy-Lightning==0.0.1) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->Easy-Lightning==0.0.1) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->Easy-Lightning==0.0.1) (3.1.2)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->Easy-Lightning==0.0.1) (2.1.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->Easy-Lightning==0.0.1) (2.31.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->Easy-Lightning==0.0.1) (9.4.0)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning->Easy-Lightning==0.0.1) (3.8.6)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->Easy-Lightning==0.0.1) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->Easy-Lightning==0.0.1) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->Easy-Lightning==0.0.1) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->Easy-Lightning==0.0.1) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->Easy-Lightning==0.0.1) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->Easy-Lightning==0.0.1) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->Easy-Lightning==0.0.1) (1.3.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning->Easy-Lightning==0.0.1) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning->Easy-Lightning==0.0.1) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning->Easy-Lightning==0.0.1) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning->Easy-Lightning==0.0.1) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning->Easy-Lightning==0.0.1) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning->Easy-Lightning==0.0.1) (1.3.1)\n","Building wheels for collected packages: Easy-Lightning\n","  Building wheel for Easy-Lightning (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for Easy-Lightning: filename=Easy_Lightning-0.0.1-py3-none-any.whl size=44822 sha256=60be51eca5004323d406d5ecc6da9e66274b48577007286a730eaee8b87196fb\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-p4lm40l5/wheels/45/e1/df/22ee52a5c3d810c3aef532dd7d74b31c8d4496b9f73f747eaf\n","Successfully built Easy-Lightning\n","Installing collected packages: lightning-utilities, torchmetrics, pytorch_lightning, Easy-Lightning\n","Successfully installed Easy-Lightning-0.0.1 lightning-utilities-0.9.0 pytorch_lightning-2.1.1 torchmetrics-1.2.0\n","Collecting pytorch-lightning==2.0.9\n","  Downloading pytorch_lightning-2.0.9-py3-none-any.whl (727 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m727.7/727.7 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==2.0.9) (1.23.5)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==2.0.9) (2.1.0+cu118)\n","Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==2.0.9) (4.66.1)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==2.0.9) (6.0.1)\n","Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==2.0.9) (2023.6.0)\n","Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==2.0.9) (1.2.0)\n","Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==2.0.9) (23.2)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==2.0.9) (4.5.0)\n","Requirement already satisfied: lightning-utilities>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==2.0.9) (0.9.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning==2.0.9) (2.31.0)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning==2.0.9) (3.8.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning==2.0.9) (3.13.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning==2.0.9) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning==2.0.9) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning==2.0.9) (3.1.2)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning==2.0.9) (2.1.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.0.9) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.0.9) (3.3.2)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.0.9) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.0.9) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.0.9) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.0.9) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.0.9) (1.3.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->pytorch-lightning==2.0.9) (2.1.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning==2.0.9) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning==2.0.9) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning==2.0.9) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->pytorch-lightning==2.0.9) (1.3.0)\n","Installing collected packages: pytorch-lightning\n","  Attempting uninstall: pytorch-lightning\n","    Found existing installation: pytorch-lightning 2.1.1\n","    Uninstalling pytorch-lightning-2.1.1:\n","      Successfully uninstalled pytorch-lightning-2.1.1\n","Successfully installed pytorch-lightning-2.0.9\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n","Collecting scikit-learn\n","  Downloading scikit_learn-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n","Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.3)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n","Installing collected packages: scikit-learn\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.2.2\n","    Uninstalling scikit-learn-1.2.2:\n","      Successfully uninstalled scikit-learn-1.2.2\n","Successfully installed scikit-learn-1.3.2\n"]}],"source":["if connect_to_drive:\n","    # Install github code\n","    !pip install git+https://github.com/fed21/easy_lightning.git\n","    # !pip install git+https://github.com/siciliano-diag/data_utils.git\n","    # !pip install git+https://github.com/siciliano-diag/exp_utils.git\n","    # !pip install git+https://github.com/siciliano-diag/torch_utils.git\n","\n","    # Install the pytorch_lightning library\n","    !pip install pytorch-lightning==2.0.9\n","\n","    !pip install --upgrade scikit-learn\n"]},{"cell_type":"markdown","metadata":{"id":"llsyZg59yyiX"},"source":["### Imports"]},{"cell_type":"markdown","metadata":{"id":"kMHIBKbq9cMF"},"source":["The script imports the following libraries and modules:\n","\n","- numpy (as np): Used for numerical computations, particularly array manipulation and mathematical operations.\n","- pandas (as pd): Used for data manipulation and analysis, providing powerful data structures and tools.\n","- matplotlib.pyplot (as plt): A sub-library of Matplotlib, used for creating various types of data visualizations, such as plots and charts.\n","- os: Allows interaction with the operating system, such as working with files, directories, and environment variables.\n","- sys: Provides access to system-specific parameters and functions, enabling control over the Python runtime environment.\n","- torch: The core library for PyTorch, which is a widely used deep learning framework in Python for building and training neural networks.\n","- The two commented-out import statements, from copy import deepcopy and import pickle, suggest that these functionalities might have been used in the past but are currently not being utilized in the script."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U0GsBSD6yz9y"},"outputs":[],"source":["# Put all imports here\n","\n","# Import NumPy library, commonly used for numerical computations and array manipulation.\n","import numpy as np\n","\n","# Import pandas library, widely used for data manipulation and analysis.\n","import pandas as pd\n","\n","# Import matplotlib.pyplot from Matplotlib, used for creating data visualizations and plotting.\n","import matplotlib.pyplot as plt\n","\n","# The following imports are commented out and not currently in use, but they are left for reference:\n","# #from copy import deepcopy: This import statement would bring in the 'deepcopy' function from the 'copy' module,\n","# which allows creating a deep copy of objects to avoid modifying the original data accidentally.\n","\n","# #import pickle: This import statement would allow working with the pickle module, which is used for\n","# serializing and deserializing Python objects, i.e., converting objects to a byte stream and vice versa.\n","\n","# Import os module, used for interacting with the operating system, such as managing files and directories.\n","import os\n","\n","# Import sys module, used to access system-specific parameters and functions.\n","import sys\n","\n","# Import torch library, which is the main library for working with PyTorch, a popular deep learning framework.\n","import torch\n","from torchvision.models.resnet import BasicBlock\n","from torch import nn\n","import pytorch_lightning as pl\n","\n","# Import pprint function from the pprint module, used for pretty-printing data structures.\n","from pprint import pprint\n","\n","# Import deepcopy for object copies\n","from copy import deepcopy\n"]},{"cell_type":"markdown","metadata":{"id":"mnSShc_Yy4lr"},"source":["### Definition of paths\n","This is to define the paths to store data, configurations, plots, models and results.\n","\n","Locally if Google Drive is not connected."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WRYc5NEeyjQ8"},"outputs":[],"source":["# Define the project folder path and set it to the parent directory of the current location.\n","project_folder = \"../\" # Used if the notebook is run locally to define the right paths\n","\n","# If connect_to_drive is True, update the project_folder to point to the specific folder in Google Drive.\n","if connect_to_drive:\n","    project_folder = \"/content/gdrive/Shareddrives/Carmignani - Overparametrization thesis\" #Name of Shared Drive folder\n","    #project_folder = \"/content/gdrive/MyDrive/<MyDriveName>\" #Name of MyDrive folder\n","\n","# The cfg_folder will contain hyperparameter configurations.\n","# It is located inside the project_folder.\n","cfg_folder = os.path.join(project_folder, \"cfg\")\n","\n","# The data_folder will contain raw and preprocessed data.\n","# It is also located inside the project_folder.\n","data_folder = os.path.join(project_folder, \"data\")\n","\n","# The raw_data_folder will contain the raw data.\n","# It is a subfolder within the data_folder.\n","raw_data_folder = os.path.join(data_folder, \"raw\")\n","\n","# The processed_data_folder will contain the preprocessed data.\n","# It is another subfolder within the data_folder.\n","processed_data_folder = os.path.join(data_folder, \"processed\")\n","\n","# The source_folder will contain all essential source code.\n","# It is located inside the project_folder.\n","source_folder = os.path.join(project_folder, \"src\")\n","\n","# The out_folder will contain all outputs, such as models, results, plots, etc.\n","# It is also located inside the project_folder.\n","out_folder = os.path.join(project_folder, \"out\")\n"]},{"cell_type":"markdown","metadata":{"id":"QuDYazsGIkCm"},"source":["### Packages:\n","\n","data_utils: A package that provides utilities and functions for working with data, possibly for data preprocessing, augmentation, or data loading.\n","\n","exp_utils: A package that contains utilities and tools for managing and organizing machine learning experiments, such as logging experiment results and managing experiment configurations.\n","\n","torch_utils: A package that likely provides utility functions and classes for working with PyTorch, a popular deep learning library.\n","\n","pytorch_lightning: A separate library that simplifies the process of training PyTorch models by abstracting away boilerplate code and providing useful features for distributed training, GPU acceleration, and more."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J0eAhR-T6vDl"},"outputs":[],"source":["# Importing all packages after GitHub download\n","import data_utils, exp_utils, torch_utils"]},{"cell_type":"markdown","metadata":{"id":"B4fhGkp14CSb"},"source":["### Import local code from the Drive"]},{"cell_type":"markdown","metadata":{"id":"f7YJ8yc4bk_b"},"source":["This code snippet deals with importing modules from a custom source folder, rather than installing packages via pip install from external sources like GitHub as before.\n","\n","*Differences from installing via pip install from GitHub:*\n","\n","  When you use pip install to install packages from GitHub or any other source, it installs the package and its dependencies globally or within a virtual environment. The installed package becomes part of Python's standard search path, and you can import the package from anywhere in your code without explicitly manipulating sys.path. The installed package can also be accessed by other projects or scripts running in the same Python environment.\n","\n","  On the other hand, the code in the provided snippet deals with importing modules from a custom source folder that might not be part of the global Python path. It allows importing specific modules from the project_folder without a formal installation step. This approach can be useful during development when you want to work with local code changes and test them without the need for package installation and updates. However, it may require more manual management and is typically used for custom development purposes rather than using pre-packaged libraries from external sources."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":394,"status":"ok","timestamp":1700044506390,"user":{"displayName":"Federico Siciliano","userId":"13460778358604487896"},"user_tz":-60},"id":"LrX3FM7szllL","outputId":"8618892e-23a1-4bf4-e505-53af60c04779"},"outputs":[{"output_type":"stream","name":"stdout","text":["['/content/gdrive/Shareddrives/Carmignani - Overparametrization thesis', '/content', '/env/python', '/usr/lib/python310.zip', '/usr/lib/python3.10', '/usr/lib/python3.10/lib-dynload', '', '/usr/local/lib/python3.10/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.10/dist-packages/IPython/extensions', '/root/.ipython', '/tmp/tmppmpflu11']\n"]}],"source":["# To import from src of Google drive a utils library (now not present)\n","\n","# Attach the source folder to the start of sys.path\n","sys.path.insert(0, project_folder)\n","print(sys.path)  # View the path and verify\n","\n","# Import from src directory: to be used if we want to import utilitis from src folder\n","# from src import utils\n","\n","# Change the current working directory to source_folder\n","os.chdir(source_folder)"]},{"cell_type":"markdown","metadata":{"id":"DIslF_wh31z2"},"source":["## Main\n","1.   Load configuration\n","2.   Data preparation\n","3.   Model\n","4.   Experiment check\n","5.   Training\n","6.   Test\n","7.   Save experiment"]},{"cell_type":"markdown","metadata":{"id":"78__SEBZ3NuK"},"source":["### Load configuration\n","The code loads a configuration using the 'load_configuration' function from the 'exp_utils.cfg' module. The loaded configuration object is stored in the 'cfg' variable.\n","\n","*An experiment with a name (\"experiment\") can be used for different configurations, when a change is not affecting the configuration parameters but it is a code-based change, then create a new experiment name*."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":337,"status":"ok","timestamp":1700044695437,"user":{"displayName":"Federico Siciliano","userId":"13460778358604487896"},"user_tz":-60},"id":"EwhL_UapYFX9","outputId":"461a061f-0ae1-4d7a-fab7-1ceae2b6ba16"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'__exp__': {'name': 'november_10',\n","  'project_folder': '../',\n","  'key_len': 16,\n","  'key_prefix': '',\n","  '__nosave__': {'model.loader_params.num_workers': None,\n","   'model.trainer_params.accelerator': None,\n","   'model.trainer_params.enable_checkpointing': None,\n","   'model.trainer_params.logger': None,\n","   'model.trainer_params.callbacks.0.ModelCheckpoint.dirpath': None,\n","   'model.trainer_params.callbacks.0.ModelCheckpoint.filename': None}},\n"," 'data': {'name': 'CIFAR10',\n","  'source': 'torchvision',\n","  'noise_level': 0.2,\n","  'merge_before_split': False,\n","  'split_keys': {'train_x': ['train_x', 'val_x'],\n","   'train_y': ['train_y', 'val_y']},\n","  'test_sizes': [0.2],\n","  'split_random_state': 21094,\n","  'one_hot_encode': True,\n","  'scaling': 'MinMax'},\n"," 'model': {'name': 'resnet18',\n","  'num_parameters': [64, 32, 16, 8, 4, 2, 1],\n","  'torchvision_params': {'weights': None},\n","  'optimizer': {'name': 'Adam', 'params': {'lr': 0.001}},\n","  'loss': 'ForwardNRL',\n","  'metrics': ['SoftLabelsAccuracy'],\n","  'log_params': {'on_epoch': True},\n","  'loader_params': {'batch_size': 128, 'num_workers': 32},\n","  'trainer_params': {'max_epochs': 4000,\n","   'callbacks': [{'ModelCheckpoint': {'save_top_k': 1,\n","      'save_last': True,\n","      'monitor': 'val_loss/dataloader_idx_0',\n","      'mode': 'min',\n","      'dirpath': '..//out/models/november_10/',\n","      'filename': 'best'}}],\n","   'accelerator': 'gpu',\n","   'enable_checkpointing': True,\n","   'logger': {'name': 'CSVLogger',\n","    'params': {'save_dir': '..//out/log/november_10/'}}}}}"]},"metadata":{},"execution_count":7}],"source":["# Load the configuration using the 'load_configuration' function from the 'exp_utils.cfg' module\n","cfg = exp_utils.cfg.load_configuration()\n","\n","cfg  # Display the loaded configuration object"]},{"cell_type":"markdown","metadata":{"id":"a8UTqAnF3NuK"},"source":["### Data Preparation and Label Noise Injection\n","\n","This code segment carries out the following steps:\n","\n","1. **Configuration Update:** It updates the \"data_folder\" configuration in the `cfg` dictionary with the value of the 'raw_data_folder' variable.\n","\n","2. **Data Loading:** The code loads data using the configuration settings from `'cfg[\"data\"]'`.\n","\n","3. **Train Data Shape:** It displays the shape of the 'train_x' data array, representing the input training images.\n","\n","4. **One-Hot Encoding Example:** The code provides an example of a one-hot encoded class label from the 'train_y' array.\n","\n","5. **Noise Configuration Check:** It checks whether noise is enabled in the configuration and prints the result as `noise_enabled`.\n","\n","6. **Label Noise Injection:** If noise is enabled and specific conditions are met (CIFAR10 dataset and one-hot encoding enabled), the code introduces label noise. It does this by randomly changing labels to simulate noise based on the 'noise_level' parameter.\n","\n","7. **Data Loader Preparation:** After loading data and potentially injecting label noise, the code prepares data loaders for training. These loaders are created based on the loaded data and loader parameters from 'cfg[\"model\"][\"loader_params\"]'.\n","\n","8. **Example Image Display:** The code extracts an example image with a shape of (3, 32, 32) from the training data. The example can be changed by modifying the `example_index` variable. It also displays the image in a (32, 32, 3) format using `matplotlib.pyplot.imshow()`, with the title showing \"3x32x32 Image\" and the axes turned off for better visualization.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":706},"executionInfo":{"elapsed":30864,"status":"ok","timestamp":1700044805390,"user":{"displayName":"Federico Siciliano","userId":"13460778358604487896"},"user_tz":-60},"id":"c_ccViub1bvQ","outputId":"16dc2d79-965f-4961-f6e9-620fcf3a60c3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[[0. 0. 0. ... 0. 0. 1.]\n"," [1. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," ...\n"," [0. 0. 0. ... 1. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]] 40000\n","Shape of train data:  torch.Size([40000, 3, 32, 32])\n","Shape of val data:  torch.Size([10000, 3, 32, 32])\n","Shape of test data:  torch.Size([10000, 3, 32, 32])\n","Example of one-hot encoding:  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","Printing some examples of noise added:  0.2  noise\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch_utils/preparation.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  features = torch.tensor(data[data_keys[0]], dtype=torch.float32)\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Shape of the printable image: torch.Size([3, 32, 32])\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 600x300 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["# Update the \"data_folder\" configuration value with the 'data_folder' variable\n","cfg[\"data\"][\"data_folder\"] = raw_data_folder\n","\n","# Load data using the configuration settings from 'cfg[\"data\"]'\n","data = data_utils.data.load_data(**cfg[\"data\"])\n","\n","# Needed for next parts\n","TARGETS = data['train_y'] #Targets\n","NUM_EXAMPLES = data['train_x'].shape[0] #Number of examples in training\n","print(TARGETS,NUM_EXAMPLES)\n","# Print the shape of the 'train_x' data and 'test_x' data\n","print(\"Shape of train data: \", data['train_x'].shape)\n","print(\"Shape of val data: \", data['val_x'].shape)\n","print(\"Shape of test data: \", data['test_x'].shape)\n","print(\"Example of one-hot encoding: \", data['train_y'][1])  # Print an example of a one-hot encoded class label\n","\n","# Add noise if both CIFAR-10 dataset, noise, and one-hot encoding are enabled\n","assert cfg[\"data.name\"]==\"CIFAR10\", \"Noise enabled just for CIFAR-10\"\n","assert cfg[\"data.one_hot_encode\"]==True, \"Noise enabled just for one-hot encoded data\"\n","\n","noise_level = cfg[\"data\"].get(\"noise_level\", 0.0)  # Default noise level is 0.0\n","\n","print(\"Printing some examples of noise added: \", noise_level, \" noise\")\n","for i in range(len(data['train_y'])):\n","    if np.random.rand() < noise_level:\n","        # Find the original label's index\n","        original_index = np.argmax(data['train_y'][i])\n","\n","        # Get a random index that is not the original one\n","        new_index = np.random.choice([j for j in range(10) if j != original_index])\n","\n","        # Create a random one-hot encoded class label based on the new index\n","        random_class = np.zeros(10)\n","        random_class[new_index] = 1\n","\n","        #print(\"Old label: \", data['train_y'][i])\n","        data['train_y'][i] = random_class\n","        #print(\"New label: \", data['train_y'][i],\"\\n\")\n","\n","# Prepare data loaders for training using the loaded data and specified loader parameters\n","loaders = torch_utils.preparation.prepare_data_loaders(data, cfg[\"model\"][\"loader_params\"])\n","\n","# Extract the example image with shape (3, 32, 32)\n","example_index = 10  # You can change this to view different examples\n","example_image_3x32x32 = data['train_x'][example_index]\n","example_image_32x32x3 = np.transpose(example_image_3x32x32, (1, 2, 0))\n","original_one_hot_label = data['train_y'][example_index]\n","\n","# Print the shape of the example image (optional)\n","print(\"Shape of the printable image:\", example_image_3x32x32.shape)\n","\n","# Display the 3x32x32 image\n","plt.figure(figsize=(6, 3))\n","plt.subplot(1, 2, 1)\n","plt.imshow(example_image_32x32x3)  # Display as (32, 32, 3)\n","plt.title(\"3x32x32 Image\")\n","plt.axis('off')\n","\n","# Show both displayed images\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"rxzWJNfg3NuL"},"source":["### Model parameters\n","This code snippet manages the configuration and initialization of the neural network model:\n","\n","The first line updates the \"in_channels\" value in the model configuration. This update ensures that the number of input channels matches the number of channels in the training images. It aligns the model's input layer with the image data's channel dimension.\n","\n","The second line updates the \"out_features\" value in the model configuration. This update ensures that the number of output features (classes) matches the number of classes in the training labels. It ensures the model's output layer aligns with the classes in the data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cW-hy-w5NbS6"},"outputs":[],"source":["# Update the number of input channels in the model configuration based on the number of channels in the training data\n","cfg[\"model\"][\"in_channels\"] = data[\"train_x\"].shape[1]\n","\n","# Update the number of output features (classes) in the model configuration based on the number of features in the training labels\n","cfg[\"model\"][\"out_features\"] = data[\"train_y\"].shape[1]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":390,"status":"ok","timestamp":1700044816359,"user":{"displayName":"Federico Siciliano","userId":"13460778358604487896"},"user_tz":-60},"id":"u4lSMo-4CgCJ","outputId":"fdf1efba-df40-4110-b0ba-3e5e52cb45c9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of parameters in the model: [64, 32, 16, 8, 4, 2, 1]\n"]}],"source":["print(\"Number of parameters in the model:\", cfg[\"model\"][\"num_parameters\"])  # Print the number of parameters level (k) specified in the config"]},{"cell_type":"markdown","metadata":{"id":"N-SOc3f-USN0"},"source":["### Change model size\n","\n","We want to be able to define a family of ResNet18s of increasing size as follows. We follow the Preactivation ResNet18 architecture of He et al. (2016), using 4 ResNet blocks, each consisting of two BatchNorm-ReLU-Convolution layers. The layer widths for the 4 blocks are [k, 2k, 4k, 8k] for varying k ∈ N but the strides are not [1, 2, 2, 2] since following PyTorch ResNet18 model. The standard ResNet18 corresponds to k = 64 convolutional channels in the first layer.\n","\n","Here the configuration has the num_parameters list and for each value a new configuration is created using \"sweep\" and each is trained indipendently.\n","In this way it is like if we have a list of ResNet18 models of different size."]},{"cell_type":"markdown","metadata":{"id":"W7SNp--DwtW1"},"source":["The purpose of creating the CustomResNet class and modifying the get_resnet_with_specified_num_parameters function is to adapt the ResNet architecture to a specific requirement: to obtain not only the final output of the network but also the feature representation from the layer before the last fully connected (fc) layer."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_rna131sFii8"},"outputs":[],"source":["class CustomResNet(nn.Module):\n","    def __init__(self, original_model, encoder_features):\n","        super().__init__()\n","        self.features = nn.Sequential(*list(original_model.children())[:-1])  # Exclude the original fc layer\n","        self.fc = original_model.fc\n","        self.encoder_features = encoder_features  # Set encoder_features from the input\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        # Flatten for input to the fc layer\n","        x = torch.flatten(x, 1)\n","        # Save the features before the fc layer for later use\n","        pre_fc_features = x\n","        # Get the final output\n","        final_output = self.fc(x)\n","        return final_output, pre_fc_features\n","\n","# This function creates the main neural network model.\n","# It utilizes the specified torchvision architecture from the configuration\n","# The get_torchvision_model function is employed, and the configuration settings from cfg[\"model\"] are passed as arguments.\n","# This function initializes the model using the chosen architecture and the provided custom parameters.\n","def get_resnet_with_specified_num_parameters(cfg):\n","    num_params = cfg[\"model\"][\"num_parameters\"]  # Get the number of parameters level (k) specified in the config\n","\n","    # Create a torchvision model based on the current configuration\n","    model = torch_utils.model.get_torchvision_model(**cfg[\"model\"])\n","\n","    # Modify the first convolutional layer to match the desired number of input channels\n","    model.conv1 = nn.Conv2d(3, num_params, kernel_size=model.conv1.kernel_size, stride=model.conv1.stride, padding=model.conv1.padding, bias=model.conv1.bias is not None)\n","    model.bn1 = nn.BatchNorm2d(num_params)\n","\n","    in_channels = num_params\n","\n","    # Loop over the different layers in the ResNet architecture\n","    for layer_name, multiplier in zip(['layer1', 'layer2', 'layer3', 'layer4'], [1, 2, 4, 8]):\n","        out_channels = num_params * multiplier\n","        layer = getattr(model, layer_name)\n","\n","        # Loop over the blocks within the current layer\n","        for i, block in enumerate(layer.children()):\n","            if isinstance(block, BasicBlock):\n","                if i == 0:\n","                    in_channels_for_block = in_channels\n","                else:\n","                    in_channels_for_block = out_channels\n","\n","                # Modify the convolutional layers and batch normalization layers within the block\n","                block.conv1 = nn.Conv2d(in_channels_for_block, out_channels, kernel_size=block.conv1.kernel_size, stride=block.conv1.stride, padding=block.conv1.padding, bias=block.conv1.bias is not None)\n","                block.bn1 = nn.BatchNorm2d(out_channels)\n","\n","                block.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=block.conv2.kernel_size, stride=block.conv2.stride, padding=block.conv2.padding, bias=block.conv2.bias is not None)\n","                block.bn2 = nn.BatchNorm2d(out_channels)\n","\n","                # Modify the downsample layers if they exist\n","                if block.downsample:\n","                    block.downsample[0] = nn.Conv2d(in_channels_for_block, out_channels, kernel_size=(1, 1), stride=block.conv1.stride, bias=False)\n","                    block.downsample[1] = nn.BatchNorm2d(out_channels)\n","\n","        in_channels = out_channels\n","\n","    # Modify the fully connected layer of the model\n","    model.fc = nn.Linear(in_channels, model.fc.out_features)\n","\n","    # Calculate encoder_features separately and set it as an attribute\n","    encoder_features = in_channels\n","    print(\"Encoder features in model created from cfg:\", encoder_features )\n","    custom_model = CustomResNet(model, encoder_features)\n","    return custom_model\n"]},{"cell_type":"markdown","metadata":{"id":"Ew6PH85H3NuM"},"source":["### Training\n","The training procedure emphasizing how it is necessary to place the objects within the cfg configuration and then use them to create the trainer, using a new variable to retain both the YAML configuration with values and the one with the objects in place."]},{"cell_type":"markdown","metadata":{"id":"A2D4kYbTHOVt"},"source":["Here we are going to define:\n","\n","\n","1.   Callbacks\n","\n","  *   Early Stopping\n","  *   Model Checkpoint\n","\n","\n","2.   Logger\n","  *   CSV Logger\n","\n","Then we are going to define, according to the actual configuration:\n","\n","\n","1.   Loss Function\n","\n","\n","2.   Optimizer\n","\n","After, let's create the final model set up and start training it!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"le-IfWSN3NuM"},"outputs":[],"source":["from torch_utils.losses import BackwardNRL\n","from torch_utils.losses import ForwardNRL\n","from torch_utils.losses import GCELoss\n","from torch_utils.losses import NCODLoss\n","\n","def create_and_train_model(cfg, main_module, loaders, experiment_id):\n","    # Set experiment_id in trainer_params in the configuration of the trainer\n","    trainer_params = torch_utils.preparation.prepare_experiment_id(cfg[\"model\"][\"trainer_params\"], experiment_id)\n","\n","    # Prepare callbacks and logger using the prepared trainer_params\n","    trainer_params[\"callbacks\"] = torch_utils.preparation.prepare_callbacks(trainer_params)\n","    trainer_params[\"logger\"] = torch_utils.preparation.prepare_logger(trainer_params)\n","\n","    # Prepare the trainer using the prepared trainer_params\n","    trainer = torch_utils.preparation.prepare_trainer(**trainer_params)\n","\n","    if cfg[\"model\"][\"loss\"] == \"NCODLoss\":\n","      # Define the configuration for NCODLoss\n","      print(\"Using NCODLoss..\")\n","      ncod_loss_config = {\n","        \"NCODLoss\": {\n","            \"total_epochs\": cfg[\"model\"][\"trainer_params\"][\"max_epochs\"],\n","            \"encoder_features\": main_module.encoder_features,\n","            \"num_classes\": cfg[\"model\"][\"out_features\"],\n","            \"sample_labels\": torch.argmax(torch.from_numpy(TARGETS), dim=1) ,\n","            \"num_examp\": NUM_EXAMPLES,\n","        }\n","      }\n","\n","      # Assuming `prepare_loss` can accept a dictionary with NCODLoss configuration\n","      loss = torch_utils.preparation.prepare_loss(ncod_loss_config)\n","\n","    else:\n","      # Prepare the loss function using configuration from cfg\n","      print(\"NON NCODLOSS..\")\n","      loss = torch_utils.preparation.prepare_loss(cfg[\"model\"][\"loss\"])\n","\n","    # Check if loss is an instance of GCELoss\n","    if isinstance(loss, BackwardNRL) or isinstance(loss, ForwardNRL):\n","      loss.set_noise_rate_and_classes(cfg)  # Add the parameter of cfg to it: noise rate and num_classes needed\n","      loss.create_noise_matrix()\n","      #print(loss.noise_rate, loss.num_classes, loss.matrix)\n","\n","    # Prepare the optimizer using configuration from cfg\n","    optimizer = torch_utils.preparation.prepare_optimizer(**cfg[\"model\"][\"optimizer\"])\n","\n","    # Prepare the metrics using configuration from cfg\n","    metrics = torch_utils.preparation.prepare_metrics(cfg[\"model\"][\"metrics\"])\n","\n","    # Create the model using main_module, loss, and optimizer\n","    model = torch_utils.process.create_model(main_module, loss, optimizer, metrics, cfg[\"model\"][\"log_params\"])\n","\n","    # Train the model using the prepared trainer, model, and data loaders\n","    torch_utils.process.train_model(trainer, model, loaders, val_key=[\"val\",\"test\"])\n","\n","    return trainer, model\n"]},{"cell_type":"markdown","metadata":{"id":"MDXD78pBZaLF"},"source":["### Experiments: Multiple ResNet models\n","Train, test and save multiple ResNet models with different sizes (parameter k) as presented in the paper.\n","\n","**Experiment check**\n","\n","The goal is to use the list of models corresponding to the different sizes of ResNet18 created and for each of them create an experiment and execute it.\n","\n","Each experiment is now saved in the folder \"experiment\" with a specific id, each experiment there is different w.r.t. the configuration, when a new folder is created it means a change in the code is done, not affecting only the configuration.\n","\n","**Testing**\n","\n","Test phase to obtain the metrics needed for evaluations.\n","\n","\n","**Save Experiment**\n","\n","Save the experiment id with an hash in the out/exp/experiment where a file with all ids is created avoiding repetitions."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["90eef7316e1b4752aa0ee255dd90c275","bf09c5a8f2a145f0abf71a60ff5c7a51","aa12579180f041f8ae243afa2b342282","ba136fd5290848f2baf9161d20671f84","77b9461f44b84e0c97a729eeacca2718","d07a5b3fbc1a4abd95b53676719168f1","d9c0bf9095a84bdd83cf8b9bedefb4ca","b5bba44c84184fe48903244fa621da11","123ee8f5216543339803c49fd1938fcc","8611e6f6fc1a4ee3ba9da718f26ad826","f2fadf3e2b394dc0a4d271439cc834e6","c594f63400bf40f8a02519331ab6b8d9","4b4d11d08dc7419baaa027ecd3395275","c829fdbccdeb4995bfc8ff26dcb57d79","cf8bfa52f4db4525974b543825b07d5c","0d7ce67bb6c843fc8ee244566e65f901","af4635218db44d9f8542b22e7666db0b","076f60138ed54ce7b4ae441bfa6ca171","e62f48c13b744d11a4e5b2839bcca05d","b542ccdce0a244a4a8b9d2003239bf74","7f6eed524cf04253be5c939e3025d4c0","569014b6a3654e259952fa31cd31ee06","f5b48d27cae849fa8d566d8ef3c7296a","484326dbd2314f0e9d3470b90b3f1db9","05c8b4dd6d5c4b509ca8e4ad299801e5","9ed2ebecd92044009695e156da1cd34b","e29b12f74c8642319ddecfe891f3f492","b4957750a1a14614a333ba729c532b4a","0fac533a8126432c8b85f45498e4c309","fe272a314bc64ea1b0d4bd874100f2dd","c97554f088974aa28e87e55a54d4a1ac","976ec0f6c5b443d4a9655c77fae0d04a","6e8f4378040a48e2ad1331e339d1ece3","1f9eb85437d244efbedd0d8cb8de10a0","779cbd84c933417a9a536763c442ffac","8de77f86e6044b3c96b89a9c17800a18","0491d612e77b4804971d2be377429006","31acfcb9c1094d7381fad66ced0f535c","d796e527108c486d95456622d43a30c1","a1f40ff3d0f047909dcc149ac2a37793","2521cf0a3d57411b868aaf5c95b4d692","1c428786d5fb44dd8f761cef23c1f901","4aa8b88fc71d456b9389a6c4bd222afa","f18fcb2e4ec64961a28ecb13de82b953"]},"id":"jXQIeNW6ZZk7","executionInfo":{"status":"error","timestamp":1700044961899,"user_tz":-60,"elapsed":39424,"user":{"displayName":"Federico Siciliano","userId":"13460778358604487896"}},"outputId":"6a72ae50-e64c-48a8-a37b-3c2bc21d2dea"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of parameters: 64\n","Encoder features in model created from cfg: 512\n"]},{"output_type":"stream","name":"stderr","text":["INFO:lightning_fabric.utilities.seed:Global seed set to 42\n"]},{"output_type":"stream","name":"stdout","text":["../out/exp/prova1 not found --> creating\n","Experiment already found: False ----> The experiment id is: e5sq3wMLxqTiwKxN\n","e5sq3wMLxqTiwKxN\n"]},{"output_type":"stream","name":"stderr","text":["INFO:lightning_fabric.utilities.seed:Global seed set to 42\n","INFO:lightning_fabric.utilities.seed:Global seed set to 42\n","INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"]},{"output_type":"stream","name":"stdout","text":["NON NCODLOSS..\n"]},{"output_type":"stream","name":"stderr","text":["INFO:lightning_fabric.utilities.seed:Global seed set to 42\n"]},{"output_type":"stream","name":"stdout","text":["Using automatic optimization set to:  True\n"]},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:pytorch_lightning.callbacks.model_summary:\n","  | Name        | Type         | Params\n","---------------------------------------------\n","0 | main_module | CustomResNet | 11.2 M\n","1 | loss        | ForwardNRL   | 0     \n","2 | metrics     | ModuleDict   | 0     \n","---------------------------------------------\n","11.2 M    Trainable params\n","0         Non-trainable params\n","11.2 M    Total params\n","44.727    Total estimated model params size (MB)\n"]},{"output_type":"display_data","data":{"text/plain":["Sanity Checking: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90eef7316e1b4752aa0ee255dd90c275"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Training: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c594f63400bf40f8a02519331ab6b8d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5b48d27cae849fa8d566d8ef3c7296a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f9eb85437d244efbedd0d8cb8de10a0"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py:53: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n","  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n","INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","Exception in thread Thread-12 (_pin_memory_loop):\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/pin_memory.py\", line 54, in _pin_memory_loop\n","    do_one_step()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/pin_memory.py\", line 31, in do_one_step\n","    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n","  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n","    return _ForkingPickler.loads(res)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/reductions.py\", line 355, in rebuild_storage_fd\n","    fd = df.detach()\n","  File \"/usr/lib/python3.10/multiprocessing/resource_sharer.py\", line 57, in detach\n","    with _resource_sharer.get_connection(self._id) as conn:\n","  File \"/usr/lib/python3.10/multiprocessing/resource_sharer.py\", line 86, in get_connection\n","    c = Client(address, authkey=process.current_process().authkey)\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 508, in Client\n","    answer_challenge(c, authkey)\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 752, in answer_challenge\n","    message = connection.recv_bytes(256)         # reject large message\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 216, in recv_bytes\n","    buf = self._recv_bytes(maxlength)\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n","    buf = self._recv(4)\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 383, in _recv\n","    raise EOFError\n","EOFError\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mEmpty\u001b[0m: ","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-35bf529654a3>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# # Test the trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# #test_trained_model(trainer, model, loaders)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mtorch_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# Save experiment and print the current configuration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_utils/process.py\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(trainer, model, loaders, loaders_key)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \"\"\"\n\u001b[1;32m     89\u001b[0m     \u001b[0;31m# Test the model using the trainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloaders_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;31m# Function to shutdown data loader workers in a distributed setting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    740\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lightning_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0m_verify_strategy_supports_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m         return call._call_and_handle_interrupt(\n\u001b[0m\u001b[1;32m    743\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_test_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_TunerExitException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_test_impl\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    783\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_provided\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_provided\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_connected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m         )\n\u001b[0;32m--> 785\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    786\u001b[0m         \u001b[0;31m# remove the tensors from the test results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_tensors_to_scalars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0;31m# RUN THE TRAINER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluating\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluation_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/utilities.py\u001b[0m in \u001b[0;36m_decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mcontext_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mcontext_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mloop_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_decorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/evaluation_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_run_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mdata_fetcher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_fetcher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/evaluation_loop.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mdata_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fetcher\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# creates the iterator inside the fetcher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Sequential\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# set the per-dataloader limits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fetchers.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"_PrefetchDataFetcher\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0;31m# ignore pre-fetching, it's not necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fetchers.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"_DataFetcher\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombined_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/combined_loader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_SUPPORTED_MODES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"iterator\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflattened\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/combined_loader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_current_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/combined_loader.py\u001b[0m in \u001b[0;36m_load_current_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;31m# Load a single DataLoader, prevents multiple sets of workers from starting unnecessarily\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_idx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;31m# No more iterables to step through, return an empty list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_reset\u001b[0;34m(self, loader, first_iter)\u001b[0m\n\u001b[1;32m   1109\u001b[0m             \u001b[0mresume_iteration_cnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_workers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mresume_iteration_cnt\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1111\u001b[0;31m                 \u001b[0mreturn_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1112\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ResumeIteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m                     \u001b[0;32massert\u001b[0m \u001b[0mreturn_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1282\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1284\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1285\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1143\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m                 \u001b[0mpids_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'DataLoader worker (pid(s) {pids_str}) exited unexpectedly'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 4554, 4555, 4556, 4557, 4558, 4559, 4560, 4561, 4562, 4563, 4564, 4565, 4566, 4567, 4568, 4569, 4570, 4571, 4572, 4573, 4574, 4575, 4576, 4577, 4578, 4579, 4584, 4585, 4586, 4587, 4588, 4589) exited unexpectedly"]}],"source":["# Iterate over each model and its corresponding configuration\n","# Loop over different values of num_params from a configuration sweep\n","# (cfg is updated with the current value, inside the loop. Reverts to original value after loop)\n","for num_params in cfg.sweep(\"model.num_parameters\"):\n","    # Get the current size for num_parameters\n","    print(\"Number of parameters:\", cfg[\"model\"][\"num_parameters\"])\n","\n","    # Get model with the specified number of parameters\n","    resnet_model = get_resnet_with_specified_num_parameters(cfg)\n","\n","    # Get the experiment ID based on the current configuration\n","    exp_found, experiment_id = exp_utils.exp.get_set_experiment_id(cfg)\n","    print(\"Experiment already found:\", exp_found, \"----> The experiment id is:\", experiment_id)\n","    print(cfg[\"__exp__.experiment_id\"])\n","    # Check if an experiment was found\n","    if exp_found:\n","        # Print the values of exp_found (if found = true) and experiment_id\n","        # If an experiment was found, go to next execution and display a message\n","        continue\n","    # If no experiment was found, continue with execution\n","\n","    # Create and train the model using the current configuration and ResNet model\n","    trainer, model = create_and_train_model(cfg, resnet_model, loaders, experiment_id)\n","\n","    # # Test the trained model\n","    # #test_trained_model(trainer, model, loaders)\n","    torch_utils.process.test_model(trainer, model, loaders)\n","\n","    # Save experiment and print the current configuration\n","    #save_experiment_and_print_config(cfg)\n","    exp_utils.exp.save_experiment(cfg)\n","\n","    # Print completion message\n","    print(\"An execution with a model of ResNet is completed with k =\", num_params)\n","    print(\"######################################################################\")\n","    print()"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"vscode":{"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"90eef7316e1b4752aa0ee255dd90c275":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bf09c5a8f2a145f0abf71a60ff5c7a51","IPY_MODEL_aa12579180f041f8ae243afa2b342282","IPY_MODEL_ba136fd5290848f2baf9161d20671f84"],"layout":"IPY_MODEL_77b9461f44b84e0c97a729eeacca2718"}},"bf09c5a8f2a145f0abf71a60ff5c7a51":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d07a5b3fbc1a4abd95b53676719168f1","placeholder":"​","style":"IPY_MODEL_d9c0bf9095a84bdd83cf8b9bedefb4ca","value":"Sanity Checking DataLoader 1: 100%"}},"aa12579180f041f8ae243afa2b342282":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_b5bba44c84184fe48903244fa621da11","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_123ee8f5216543339803c49fd1938fcc","value":2}},"ba136fd5290848f2baf9161d20671f84":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8611e6f6fc1a4ee3ba9da718f26ad826","placeholder":"​","style":"IPY_MODEL_f2fadf3e2b394dc0a4d271439cc834e6","value":" 2/2 [00:00&lt;00:00, 14.67it/s]"}},"77b9461f44b84e0c97a729eeacca2718":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"d07a5b3fbc1a4abd95b53676719168f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9c0bf9095a84bdd83cf8b9bedefb4ca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b5bba44c84184fe48903244fa621da11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"123ee8f5216543339803c49fd1938fcc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8611e6f6fc1a4ee3ba9da718f26ad826":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2fadf3e2b394dc0a4d271439cc834e6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c594f63400bf40f8a02519331ab6b8d9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4b4d11d08dc7419baaa027ecd3395275","IPY_MODEL_c829fdbccdeb4995bfc8ff26dcb57d79","IPY_MODEL_cf8bfa52f4db4525974b543825b07d5c"],"layout":"IPY_MODEL_0d7ce67bb6c843fc8ee244566e65f901"}},"4b4d11d08dc7419baaa027ecd3395275":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_af4635218db44d9f8542b22e7666db0b","placeholder":"​","style":"IPY_MODEL_076f60138ed54ce7b4ae441bfa6ca171","value":"Epoch 1: 100%"}},"c829fdbccdeb4995bfc8ff26dcb57d79":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_e62f48c13b744d11a4e5b2839bcca05d","max":313,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b542ccdce0a244a4a8b9d2003239bf74","value":313}},"cf8bfa52f4db4525974b543825b07d5c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f6eed524cf04253be5c939e3025d4c0","placeholder":"​","style":"IPY_MODEL_569014b6a3654e259952fa31cd31ee06","value":" 313/313 [00:08&lt;00:00, 36.54it/s, v_num=0]"}},"0d7ce67bb6c843fc8ee244566e65f901":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"af4635218db44d9f8542b22e7666db0b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"076f60138ed54ce7b4ae441bfa6ca171":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e62f48c13b744d11a4e5b2839bcca05d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b542ccdce0a244a4a8b9d2003239bf74":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7f6eed524cf04253be5c939e3025d4c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"569014b6a3654e259952fa31cd31ee06":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f5b48d27cae849fa8d566d8ef3c7296a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_484326dbd2314f0e9d3470b90b3f1db9","IPY_MODEL_05c8b4dd6d5c4b509ca8e4ad299801e5","IPY_MODEL_9ed2ebecd92044009695e156da1cd34b"],"layout":"IPY_MODEL_e29b12f74c8642319ddecfe891f3f492"}},"484326dbd2314f0e9d3470b90b3f1db9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b4957750a1a14614a333ba729c532b4a","placeholder":"​","style":"IPY_MODEL_0fac533a8126432c8b85f45498e4c309","value":"Validation DataLoader 1: 100%"}},"05c8b4dd6d5c4b509ca8e4ad299801e5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_fe272a314bc64ea1b0d4bd874100f2dd","max":79,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c97554f088974aa28e87e55a54d4a1ac","value":79}},"9ed2ebecd92044009695e156da1cd34b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_976ec0f6c5b443d4a9655c77fae0d04a","placeholder":"​","style":"IPY_MODEL_6e8f4378040a48e2ad1331e339d1ece3","value":" 79/79 [00:00&lt;00:00, 106.15it/s]"}},"e29b12f74c8642319ddecfe891f3f492":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"b4957750a1a14614a333ba729c532b4a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0fac533a8126432c8b85f45498e4c309":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fe272a314bc64ea1b0d4bd874100f2dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c97554f088974aa28e87e55a54d4a1ac":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"976ec0f6c5b443d4a9655c77fae0d04a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e8f4378040a48e2ad1331e339d1ece3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1f9eb85437d244efbedd0d8cb8de10a0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_779cbd84c933417a9a536763c442ffac","IPY_MODEL_8de77f86e6044b3c96b89a9c17800a18","IPY_MODEL_0491d612e77b4804971d2be377429006"],"layout":"IPY_MODEL_31acfcb9c1094d7381fad66ced0f535c"}},"779cbd84c933417a9a536763c442ffac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d796e527108c486d95456622d43a30c1","placeholder":"​","style":"IPY_MODEL_a1f40ff3d0f047909dcc149ac2a37793","value":"Validation DataLoader 0:   0%"}},"8de77f86e6044b3c96b89a9c17800a18":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_2521cf0a3d57411b868aaf5c95b4d692","max":79,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1c428786d5fb44dd8f761cef23c1f901","value":0}},"0491d612e77b4804971d2be377429006":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4aa8b88fc71d456b9389a6c4bd222afa","placeholder":"​","style":"IPY_MODEL_f18fcb2e4ec64961a28ecb13de82b953","value":" 0/79 [00:00&lt;?, ?it/s]"}},"31acfcb9c1094d7381fad66ced0f535c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"d796e527108c486d95456622d43a30c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1f40ff3d0f047909dcc149ac2a37793":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2521cf0a3d57411b868aaf5c95b4d692":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c428786d5fb44dd8f761cef23c1f901":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4aa8b88fc71d456b9389a6c4bd222afa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f18fcb2e4ec64961a28ecb13de82b953":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}